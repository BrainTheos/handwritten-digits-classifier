{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_digits\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "digits = load_digits()\n",
    "target = pd.Series(digits.target)\n",
    "data = pd.DataFrame(digits.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f4137055ef0>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_, axes = plt.subplots(2, 4)\n",
    "axes[0,0].imshow(data.iloc[0].values.reshape(8,8), cmap='gray_r')\n",
    "axes[0,1].imshow(data.iloc[99].values.reshape(8,8), cmap='gray_r')\n",
    "axes[0,2].imshow(data.iloc[199].values.reshape(8,8), cmap='gray_r')\n",
    "axes[0,3].imshow(data.iloc[299].values.reshape(8,8), cmap='gray_r')\n",
    "axes[1,0].imshow(data.iloc[999].values.reshape(8,8), cmap='gray_r')\n",
    "axes[1,1].imshow(data.iloc[1099].values.reshape(8,8), cmap='gray_r')\n",
    "axes[1,2].imshow(data.iloc[1199].values.reshape(8,8), cmap='gray_r')\n",
    "axes[1,3].imshow(data.iloc[1299].values.reshape(8,8), cmap='gray_r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9677233358079684"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def train(k, train_features, train_labels):\n",
    "    knn = KNeighborsClassifier(n_neighbors = k)\n",
    "    knn.fit(train_features, train_labels)\n",
    "    return knn\n",
    "\n",
    "def test(model, test_features, test_labels):\n",
    "    predictions = model.predict(test_features)\n",
    "    train_test_df = pd.DataFrame()\n",
    "    train_test_df['correct_label'] = test_labels\n",
    "    train_test_df['predicted_label'] = predictions\n",
    "    accuracy = sum(train_test_df[\"predicted_label\"] == train_test_df[\"correct_label\"])/len(train_test_df)    \n",
    "    return accuracy\n",
    "\n",
    "def cross_validate(k):\n",
    "    fold_accuracies = []\n",
    "    kf = KFold(n_splits = 4, random_state=2)\n",
    "    for train_index, test_index in kf.split(data):\n",
    "        train_features, test_features = data.loc[train_index], data.loc[test_index]\n",
    "        train_labels, test_labels = target.loc[train_index], target.loc[test_index]\n",
    "        model = train(k, train_features, train_labels)\n",
    "        overall_accuracy = test(model, test_features, test_labels)\n",
    "        fold_accuracies.append(overall_accuracy)\n",
    "    return fold_accuracies\n",
    "        \n",
    "knn_one_accuracies = cross_validate(1)\n",
    "np.mean(knn_one_accuracies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f4133736c50>]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k_values = list(range(1,10))\n",
    "k_overall_accuracies = []\n",
    "\n",
    "for k in k_values:\n",
    "    k_accuracies = cross_validate(k)\n",
    "    k_mean_accuracy = np.mean(k_accuracies)\n",
    "    k_overall_accuracies.append(k_mean_accuracy)\n",
    "    \n",
    "plt.figure(figsize=(8,4))\n",
    "plt.title(\"Mean Accuracy vs. k\")\n",
    "plt.plot(k_values, k_overall_accuracies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "def train_nn(neuron_size, train_features, train_labels):\n",
    "    mlp = MLPClassifier(hidden_layer_sizes=neuron_size, activation='logistic')\n",
    "    mlp.fit(train_features, train_labels)\n",
    "    return mlp\n",
    "\n",
    "def test(model, test_features, test_labels):\n",
    "    predictions = model.predict(test_features)\n",
    "    train_test_df = pd.DataFrame()\n",
    "    train_test_df['correct_label'] = test_labels\n",
    "    train_test_df['predicted_label'] = predictions\n",
    "    accuracy = sum(train_test_df[\"predicted_label\"] == train_test_df[\"correct_label\"])/len(train_test_df)    \n",
    "    return accuracy\n",
    "\n",
    "def cross_validate(k):\n",
    "    fold_accuracies = []\n",
    "    kf = KFold(n_splits = 4, random_state=2)\n",
    "    for train_index, test_index in kf.split(data):\n",
    "        train_features, test_features = data.loc[train_index], data.loc[test_index]\n",
    "        train_labels, test_labels = target.loc[train_index], target.loc[test_index]\n",
    "        model = train_nn(k, train_features, train_labels)\n",
    "        overall_accuracy = test(model, test_features, test_labels)\n",
    "        fold_accuracies.append(overall_accuracy)\n",
    "    return fold_accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/dataquest/system/env/python3/lib/python3.4/site-packages/sklearn/neural_network/multilayer_perceptron.py:563: ConvergenceWarning:\n",
      "\n",
      "Stochastic Optimizer: Maximum iterations reached and the optimization hasn't converged yet.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "neurons = [\n",
    "    (8,),(16,),(32,), (64,), (128,), (256,)\n",
    "]\n",
    "nn_one_layer_accuracies = []\n",
    "\n",
    "for n in neurons:\n",
    "    nn_accuracies = cross_validate(n)\n",
    "    nn_mean_accuracy = np.mean(nn_accuracies)\n",
    "    nn_one_layer_accuracies.append(nn_mean_accuracy)\n",
    "\n",
    "plt.figure(figsize=(8,4))\n",
    "plt.title(\"Mean Accuracy vs. Neurons In Single Hidden Layer\")\n",
    "\n",
    "x = [i[0] for i in neurons]\n",
    "plt.plot(x, nn_one_layer_accuracies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "neurons = [\n",
    "     (64,64), (128,128), (256,256)\n",
    "]\n",
    "nn_two_layer_accuracies = []\n",
    "\n",
    "for n in neurons:\n",
    "    nn_accuracies = cross_validate(n)\n",
    "    nn_mean_accuracy = np.mean(nn_accuracies)\n",
    "    nn_two_layer_accuracies.append(nn_mean_accuracy)\n",
    "\n",
    "plt.figure(figsize=(8,4))\n",
    "plt.title(\"Mean Accuracy vs. Neurons In Two Hidden Layers\")\n",
    "\n",
    "x = [i[0] for i in neurons]\n",
    "plt.plot(x, nn_two_layer_accuracies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cross_validate_six(k):\n",
    "    fold_accuracies = []\n",
    "    kf = KFold(n_splits = 6, random_state=2)\n",
    "    for train_index, test_index in kf.split(data):\n",
    "        train_features, test_features = data.loc[train_index], data.loc[test_index]\n",
    "        train_labels, test_labels = target.loc[train_index], target.loc[test_index]\n",
    "        model = train_nn(k, train_features, train_labels)\n",
    "        overall_accuracy = test(model, test_features, test_labels)\n",
    "        fold_accuracies.append(overall_accuracy)\n",
    "    return fold_accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "neurons = [\n",
    "     (10,10,10),(64,64,64), (128,128,128)\n",
    "]\n",
    "nn_three_layer_accuracies = []\n",
    "\n",
    "for n in neurons:\n",
    "    nn_accuracies = cross_validate_six(n)\n",
    "    nn_mean_accuracy = np.mean(nn_accuracies)\n",
    "    nn_three_layer_accuracies.append(nn_mean_accuracy)\n",
    "\n",
    "plt.figure(figsize=(8,4))\n",
    "plt.title(\"Mean Accuracy vs. Neurons In Three Hidden Layers\")\n",
    "\n",
    "x = [i[0] for i in neurons]\n",
    "plt.plot(x, nn_three_layer_accuracies)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
